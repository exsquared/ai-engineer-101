# When to Trust the Model

*How smart systems know their limits â€” and act accordingly*
---

## ğŸ¯ Why This Chapter Exists

In Chapter 3, you trained a model and saw how it drew a decision boundary â€” a line between â€œyesâ€ and â€œno.â€

But not all decisions are clear.

Some inputs land close to that boundary.
> What happens when the model isnâ€™t confident?

This chapter is about designing systems that can say:
> â€œI think itâ€™s spamâ€¦ but Iâ€™m only 60% sure.â€

And then act accordingly.

---

## ğŸ§  What Is Model Confidence?

When you call `.predict_proba()` on a model like logistic regression or Naive Bayes, it gives you a **probability**.

```python
model.predict_proba([[4.2, 1]])
# Output: [0.13, 0.87] â†’ 87% confidence in class 1
```

That number isnâ€™t magic. Itâ€™s just how far the point is from the decision boundary.

- Far from the line = confident
- Close to the line = uncertain

This is critical for real systems.

---

## ğŸ“‰ Visualizing Confidence Zones

Imagine your decision boundary as a line:
```
â† 0% confident â€”â€”â€”|â€”â€”â€” 100% confident â†’
             boundary
```
Everything near the middle (45â€“55%) is **dangerous territory**.
Thatâ€™s where misclassifications are most likely.

---

## ğŸ’¡ What Should a Smart System Do?

> ğŸ¤” If the model is 51% confident, should it act like itâ€™s 100% sure?

Of course not.

Hereâ€™s a better plan:
```python
if confidence > 0.85:
    auto_accept()
elif confidence < 0.6:
    flag_for_review()
else:
    fall_back_to_rules()
```

Youâ€™re designing not just a model â€” but a system that **knows its own limits**.

---

## ğŸ”„ Threshold Tuning â€” A Developerâ€™s Superpower

Most models default to a 50% cutoff:
```python
if prob > 0.5: predict class 1
```
But you can shift that line to make the system more conservative or aggressive.

### Example:

```python
y_scores = model.predict_proba(X_test)[:, 1]  # probability for class 1

y_custom = (y_scores > 0.7).astype(int)  # only predict 1 if very confident
```

Tuning this threshold changes everything:

- Higher threshold â†’ fewer false positives, but more misses
- Lower threshold â†’ more flags, but more risk

---

## ğŸ§ª Mini-Experiment: Try Threshold Tuning

Train a model using your support ticket data. Then try these:
```python
from sklearn.metrics import classification_report

for t in [0.3, 0.5, 0.7]:
    y_custom = (y_scores > t).astype(int)
    print(f"\nThreshold = {t}")
    print(classification_report(y_test, y_custom))
```
Youâ€™ll quickly see how your model behaves under different confidence strategies.

---

## ğŸ§  Quick Intro: What Is Naive Bayes?

Before we dive into the next classifier, here's a quick intro:

**Naive Bayes** is a fast and effective algorithm for classifying text. It works by calculating how often certain words appear in each category â€” then makes a guess based on probability.

Itâ€™s called â€œnaiveâ€ because it assumes each word contributes independently to the outcome â€” even though thatâ€™s not always true.

Despite the name, it works surprisingly well for things like spam detection or support ticket classification.

ğŸ§  Want to dig into how it works behind the scenes? Weâ€™ve got a clear explanation in the [Fun ML Toolbox](#).

---

## ğŸ® Real-World NLP Classifier with Confidence

Letâ€™s apply this to a real NLP example using Naive Bayes.

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Sample training data
tickets = ["help ASAP!", "urgent issue", "payment failed", "slow loading"]
labels = ["urgent", "urgent", "non-urgent", "non-urgent"]

vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(tickets)

model = MultinomialNB().fit(X_train, labels)

# Predict with confidence
new_ticket = vectorizer.transform(["can't login, help now"])
prediction = model.predict(new_ticket)
prediction_proba = model.predict_proba(new_ticket)

print("Prediction:", prediction)
print("Confidence scores:", prediction_proba)
```

ğŸ‰ Youâ€™ve now used `.predict_proba()` on real text. This is how modern AI systems decide when to be bold â€” and when to back off.

---

## âš™ï¸ Confidence in Production

Hereâ€™s how real teams use confidence scores:

| Confidence | Action                            |
|------------|-----------------------------------|
| > 0.9      | Auto-process, log result          |
| 0.6â€“0.9    | Flag for human review             |
| < 0.6      | Donâ€™t act â€” trigger fallback rule |

This is **how mature AI systems operate** â€” not just â€œguess and go,â€ but â€œguess, evaluate, then act.â€

---

## ğŸ”¥ Real-World Case: SmartAssist Co.

SmartAssist had an urgency classifier.

- If the model was 95%+ confident, it auto-routed tickets
- If below 60%, it flagged the ticket and asked a support agent

That simple confidence logic reduced routing errors by 70%.

---

## ğŸ“š Optional Deep Dive: â€œHow Does It Know That?â€

Feeling curious?

Ever wondered:

- How does `.predict_proba()` calculate that number?
- Why does logistic regression give smooth scores?
- How does Naive Bayes combine probabilities?

Then take a detour to the next chapter:

### ğŸ‘‰ [ğŸ› ï¸ The Fun ML Toolbox](fun_ml_toolbox.md)

> Get clear, visual explanations of vectorization, logistic regression, Naive Bayes, and more.

Not essential â€” but very helpful if you want to peek under the hood.

---

## ğŸ§  Reflection Corner

- When should a modelâ€™s output be trusted without question?
- Where in your own product could confidence thresholds improve performance?
- Can you recall a time a â€œmaybeâ€ prediction shouldâ€™ve been stopped or escalated?

---

## ğŸ“Œ Quick Summary

- `.predict_proba()` shows how confident the model is
- Confidence â‰  correctness, but it helps design safer systems
- Use thresholds and fallbacks to handle low-certainty predictions
- Great AI systems donâ€™t just predict â€” they **know when theyâ€™re unsure**

Up next: If you're curious how models calculate confidence, jump into the **Fun ML Toolbox**.
Otherwise, weâ€™ll move on to evaluating *how well* your model is performing â€” beyond just being â€œaccurate.â€