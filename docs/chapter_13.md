# Let Your Model Think and Act  
*Agents, Tool Use, and the Reasoning Loop*

---

## ğŸ§­ Why Are We Here?

Youâ€™ve built models. Youâ€™ve served them with FastAPI. Youâ€™ve retrieved documents with RAG.

But real-world questions donâ€™t always have obvious answers or clean one-shot responses. Users ask things that require multi-step thinking, calling tools, searching, calculating, retrying.

> This is where **agents** shine â€” giving LLMs the ability to think step-by-step, take actions, observe outcomes, and adapt.

Weâ€™re now entering the era of **agentic systems**.

---

## ğŸ” Before Agents: The Intent Routing Phase

Even after LLMs arrived, we still built logic-heavy, brittle systems.

The pattern looked like this:

1. Ask the LLM to return an intent:
```json
{"intent": "get_weather", "location": "London"}
```

2. Manually route in code:
```python
if intent == "get_weather":
    return get_weather(location)
elif intent == "convert_currency":
    return convert_currency(from_curr, to_curr)
else:
    return "Sorry, I can't help with that."
```

âœ… This worked.  
âŒ But it was rigid:
- Every new tool = more branching logic  
- You had to trust the intent parser completely  
- Multi-intent or follow-up tasks? Forget it  
- Hard to retry, inspect, or trace reasoning

The LLM was just an **intent extractor** â€” all logic lived in your backend.

This was better than rules, but still far from agentic thinking.

---

## âš¡ ReAct + Function Calling Changed Everything

**ReAct (Reason + Act + Observe)** lets the model:

- Think out loud
- Decide which tool to call
- Use the result to continue reasoning

**Function calling** gives the model access to real tools in a safe, structured way.

Instead of hardcoded logic, the model says:
```
Thought: I need to convert USD to INR.
Action: get_exchange_rate("USD")
Observation: 1 USD = 83 INR
Answer: Youâ€™ll get 83 rupees per dollar.
```

Now **LLMs can orchestrate logic â€” not just output text**.

---

## ğŸ§ª Mini-Exercise: Before vs After

Build this system:

- If user asks for a joke â†’ tell one
- If they ask for weather â†’ call a fake API
- If they ask for exchange rate â†’ call another function

### Step 1: Do it manually with `if`/`elif`

### Step 2: Refactor using:

- ReAct-style prompt
- Function calling with LangChain or OpenAI

### Reflect:

- What changed?
- Which version is easier to extend?
- Where does the reasoning now live?

---

## ğŸ¤– What Is an Agent?

An **agent** is an LLM system that:

1. **Thinks** about what it needs to do
2. **Chooses a tool** to take action
3. **Observes the result**
4. **Repeats or finishes**

This is called an **agent loop**.

---

## ğŸ§  Agentic Thinking

| Traditional APIs | Agentic Systems |
|------------------|-----------------|
| Developer wires logic | Model decides flow |
| Tools are hardwired | Tools are exposed and selected dynamically |
| Input â†’ logic â†’ response | Input â†’ thoughts â†’ actions â†’ response |

Agents blur the line between logic and language â€” and put decision-making inside the model.

---

## ğŸ§± Agent Design Patterns

### ğŸ§  ReAct Loop
```
Thought â†’ Action â†’ Observation â†’ Thought â†’ Answer
```

### ğŸ§  Plannerâ€“Executor

- Agent 1: plans steps
- Agent 2: executes tools

### ğŸ§  Agent-as-API-Router

Let a single LLM route requests to the right API or logic layer based on intent.

### ğŸ§  Agent-as-Backend-Brain

Instead of chaining APIs in microservices, the agent decides what to call, when, and in what order.

---

## ğŸ”§ What Are Tools?

In LangChain or OpenAI:
> A **tool** is a function the model can call.

You define:
```python
@tool
def get_weather(city: str) -> str:
    return "Sunny and 23Â°C in Delhi"
```

And the model decides when to call it â€” with what args.

---

## ğŸ› ï¸ Build a Tool-Using Agent

```python
from langchain.agents import tool

@tool
def get_exchange_rate(currency: str) -> str:
    return "1 USD = 83 INR"
```

Then:
```python
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, AgentType

llm = ChatOpenAI(model="gpt-4")
agent = initialize_agent(
    tools=[get_exchange_rate],
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True,
)

agent.run("Convert $1 to INR")
```

âœ… Now the model thinks + acts â€” not just responds.

---

## ğŸ§  When Do Agents Replace Microservices?

Sometimes the LLM + tool layer **is** your backend logic.

| Task | Traditional Microservice | Agentic Alternative |
|------|---------------------------|----------------------|
| Intent classification | Flask route or model | LLM with ReAct routing |
| Email triage | Rules or model â†’ API call | Agent chooses tool based on message |
| Q&A + math + lookup | Separate endpoints | One agent choosing which to do |

> Youâ€™re no longer hardwiring decision trees â€” youâ€™re exposing tools and letting the agent drive.

Agents let you **move logic from code into controlled language** â€” making systems more flexible.

---

## ğŸ§ª Microproject: Agentify Your App

Take a mini FastAPI app with 2â€“3 tools:

- Joke generator
- Weather API stub
- Exchange rate calculator

Build:
âœ… A hardcoded `if/elif` version  
âœ… An agent-driven version using function calling  
âœ… Log `thought`, `action`, `observation` at each step

Bonus:

- Add retry if a tool fails
- Add a loop limit (max 5 steps)

---

## ğŸ§  Reflection Questions

1. What logic can you move from backend code into a prompt?
2. When should you *not* let the model pick tools?
3. Where might agents introduce risk or fragility?

---

## âœ… Best Practices for Agent Design

âœ… Tools must be deterministic, safe, and well-typed  
âœ… Log every thought, action, observation  
âœ… Use short tool names + descriptions for LLM clarity  
âœ… Cap max steps â€” agents can loop forever if youâ€™re not careful  
âœ… Fallback to static logic when confidence is low  
âœ… Let tools fail gracefully â€” model should adapt

> ğŸ” Donâ€™t give agents the kitchen sink. Give them power **with guardrails**.

---

## âœ… You Now Know:

âœ… Why agents changed how we build AI systems  
âœ… How to build a reasoning + acting loop  
âœ… How to expose tools to the model  
âœ… How to design agentic workflows that feel like dynamic APIs  
âœ… When to replace brittle logic with LLM reasoning