# Let LLMs Act, Not Just Answer  
### _Agents, Reasoning Loops, and Tool Use_

---

## ğŸ§­ Why Are We Here?

Up until now, weâ€™ve used LLMs like really smart parrots.

You feed them some context.  
They give you a great answer.  
Thatâ€™s it. One-shot, one-turn.

But what if we want more?

> â€œSearch Google for flight options, check the weather, compare it to my calendar, and suggest the best time to travel.â€

This isnâ€™t just Q&A.  
This is **multi-step reasoning + tool use**.  
You donâ€™t want the model to just answer.  
You want it to **think**, **decide**, and **act**.

Thatâ€™s the world of **agents**.

---

## ğŸ¤– What Is an Agent?

An **Agent** is an LLM system that:
1. Reads the user's intent  
2. Plans a series of actions  
3. Uses tools (APIs, functions, calculators, etc.)  
4. Loops until it reaches a final answer

Think of it like:
- The LLM is the brain  
- The tools are its hands  
- The agent system is the â€œnervous systemâ€ orchestrating decisions

---

## ğŸ§  Real-World Analogy

You: â€œWhatâ€™s the cheapest non-stop flight from NYC to SF next Friday under 5 hours?â€

Your intern:
1. Opens Google Flights  
2. Applies filters  
3. Looks at durations  
4. Picks the cheapest one  
5. Summarizes it for you

They donâ€™t know the answer _a priori_ â€” they **figure it out by taking actions**.

---

## ğŸ” Agent Loop in Plain English

Every time the agent thinks:
1. **Observe**: Whatâ€™s the current task or question?  
2. **Think**: What tool do I need?  
3. **Act**: Use a tool (e.g., search API, calculator)  
4. **Read result**: Did it solve the task?  
5. **Repeat**: Until it reaches an answer

This is called a **Reasoning-Acting Loop**.

---

## ğŸ§° Tools You Can Give an Agent

| Tool Type     | Example                 |
|---------------|-------------------------|
| Calculator    | `"4 * 17"`              |
| Python code   | `"Sort by date"`        |
| Web search    | `"Scrape this page"`    |
| File reader   | `"Read the invoice PDF"`|
| Custom API    | `"GET /user/profile"`   |

Each tool is just a **function** the agent is allowed to call.

---

## ğŸ› ï¸ Frameworks That Help

| Framework             | Purpose                                    |
|------------------------|--------------------------------------------|
| **LangChain**          | Build agents from pre-built toolkits       |
| **OpenAI Function Calling** | Let GPT â€œchooseâ€ and call your functions |
| **CrewAI / AutoGen**   | Multi-agent orchestration (advanced)       |

Weâ€™ll focus on **LangChain + OpenAI Function Calling** for now.

---

## âš™ï¸ How Function Calling Works (OpenAI)

1. You define functions you want to expose  
2. The LLM is told about their names and parameters  
3. It chooses one and sends a structured JSON payload  
4. Your code runs the function and feeds the result back  
5. The model continues reasoning with the new info

> The model â€œthinksâ€ and _asks_ to use tools â€” your code runs the tool for it.

---

## ğŸ’» Letâ€™s Build a Simple Agent

### ğŸ§® Step 1: Define Tools

```python
from langchain.agents import tool

@tool
def get_exchange_rate(currency: str) -> str:
    if currency == "USD":
        return "1 USD = 83 INR"
    return f"No data for {currency}"
```

---

### ğŸ§  Step 2: Create the Agent

```python
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent, AgentType

llm = ChatOpenAI(model="gpt-4")

agent = initialize_agent(
    tools=[get_exchange_rate],
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True,
)

agent.run("What is the exchange rate for USD?")
```

---

### ğŸ” Whatâ€™s Happening Under the Hood?

1. The LLM reads your query  
2. It decides to call `get_exchange_rate()`  
3. It sends the input `"USD"`  
4. Your Python function runs  
5. The result is injected back into the prompt  
6. The LLM completes the answer using the result

You didnâ€™t hardcode any logic â€” the LLM figured it out.

---

## ğŸ§  Agents vs RAG

| Use Case        | RAG                            | Agent                                 |
|------------------|----------------------------------|----------------------------------------|
| Need doc info?   | âœ… Use vector search             | â– Only if you combine with RAG         |
| Need to act?     | â– No tool usage                 | âœ… Call APIs, calculate, fetch, etc.    |
| Need both?       | âœ… Combine RAG + Agents          | âœ… Smartest choice                      |

---

## âš ï¸ Gotchas & Design Tips

- **Tool reliability** matters â€” bad APIs = broken agents  
- **Loop limits** prevent infinite reasoning  
- **Logging** is essential â€” observe the agentâ€™s thought chain  
- **Prompting still matters** â€” agents need structure and constraints

---

## ğŸ”¬ What Advanced Agents Can Do (Preview)

- Chain tools together  
- Maintain short-term memory  
- Work as multiple agents with roles  
- Execute plans from scratch (planner/executor)  
- Monitor their own uncertainty and retry

---

## ğŸ“¦ Patterns Emerging from Agents

### ğŸ”¹ Toolformer

Models trained not just to generate text â€” but to **learn when and how to use tools** during pretraining.  
Instead of hard-coding tool use, Toolformer _predicts_ when a tool is needed and automatically integrates API usage into its generation.  
Great for automating complex decision + data workflows.

### ğŸ”¹ ReAct

Short for **Reasoning + Acting**. A prompt strategy where the model moves step by step:

```
Thought: I need to check the current exchange rate  
Action: get_exchange_rate("USD")  
Observation: 1 USD = 83 INR  
Thought: Now I can respond  
Answer: The rate is 83 INR
```

ReAct is helpful when you want **transparent, debuggable steps** and looping behavior.

### ğŸ”¹ Planner-Executor

One LLM **plans the high-level steps**, another **executes** them.  
For example:
- Planner: â€œStep 1: Get exchange rate. Step 2: Calculate budget. Step 3: Suggest destination.â€  
- Executor: Runs each step using tools or APIs.

This pattern:
- Separates concerns  
- Enables modular debugging  
- Scales better in complex tasks

---

## ğŸ§­ Whatâ€™s Coming Next: Think Beyond the Model

Now that youâ€™ve mastered retrieval and reasoning, the next frontier is **system-level intelligence**. Here are key architecture patterns you'll encounter:

### ğŸ§± MCP â€” Model Context Protocol

A **spec for how you feed models information**. MCP defines:
- What context types a model should receive (e.g. user history, environment, goals)
- How that context is prioritized, formatted, and trimmed to fit the token budget
- How to trace which context influenced which outputs

Itâ€™s like OpenAPI â€” but for prompts.

### ğŸ” A2A â€” Agent-to-Agent Communication

Just like services talk via APIs, agents can talk via language.
- A Planner Agent can send instructions to Worker Agents
- Agents with different capabilities or memory scopes can cooperate

Youâ€™ll learn how to **route subtasks**, track ownership, and design protocols between agents.

### ğŸ§  Context Engineering

LLMs are context-hungry. The trick isnâ€™t just more tokens â€” itâ€™s **better tokens**.

Youâ€™ll learn:
- How to select the right document chunks
- How to rank/filter based on user intent
- How to format context (inline vs. structured)

This is where **retrieval meets UX meets architecture**.

---

## ğŸ§  Recap: You Now Knowâ€¦

âœ… What agents are and why they matter  
âœ… How tool-calling works using function APIs  
âœ… How the reasoning-act loop works  
âœ… How to build agents with LangChain  
âœ… When to use agents vs RAG  
âœ… Common agent patterns  
âœ… Whatâ€™s coming next at the system level

---

## â“Reflection Questions

1. When should you prefer RAG over agents? When should you combine both?  
2. What real-world apps in your org could benefit from tool-calling?  
3. What risks should you monitor in agent loops and tool chaining?  
4. How would you explain the ReAct pattern to a teammate?  
5. How might MCP help your engineering team make LLM use more robust and auditable?

---

## ğŸ§ª Mini Quiz

**Q1.** What does an agent do that a normal LLM call doesnâ€™t?  
âœ… c) Plans and calls tools

**Q2.** Why are function-calling APIs safer than raw prompting?  
âœ… b) You get structured outputs

---

## ğŸ§ª Microproject

Build a **Currency & Travel Advisor Agent**:
- Ask the user: â€œWhat currency do you want to check?â€  
- Use `get_exchange_rate()` to respond  
- Add another tool: `get_travel_advice(country)`  
- Chain them: currency â†’ visa â†’ safety tips  
- Log the agentâ€™s full reasoning steps

---

## ğŸ‰ Core Track Finale: What Youâ€™ve Built

Youâ€™ve now created:
- A confident classifier  
- A doc-aware assistant (RAG)  
- A tool-using agent  
- And built the foundation of **real LLM applications**

---

## ğŸ”œ Next Chapter: Let the Model See

Next, youâ€™ll explore **GPT-4V and multimodal models** â€” where LLMs can read images, screenshots, graphs, and more.

Welcome to the GenAI Playground.